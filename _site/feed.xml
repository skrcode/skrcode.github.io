<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.6.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-09-16T13:56:17+05:30</updated><id>http://localhost:4000/</id><title type="html">skrcode.github.io</title><subtitle>Software Engineer, Algorithmic Programmer, NLP enthusiast</subtitle><entry><title type="html">Discount Offer using dynamic programming?</title><link href="http://localhost:4000/https:/medium.com/myntra-engineering/discount-offers-using-dynamic-programming-ba383098c628" rel="alternate" type="text/html" title="Discount Offer using dynamic programming?" /><published>2018-07-22T00:00:00+05:30</published><updated>2018-07-22T00:00:00+05:30</updated><id>http://localhost:4000/https:/medium.com/myntra-engineering/discount</id><content type="html" xml:base="http://localhost:4000/https:/medium.com/myntra-engineering/discount-offers-using-dynamic-programming-ba383098c628">&lt;p&gt;How we at Myntra solved a critical business problem in discounting using dynamic programming.&lt;/p&gt;</content><author><name></name></author><summary type="html">How we at Myntra solved a critical business problem in discounting using dynamic programming.</summary></entry><entry><title type="html">How chocolate and a slack-bot motivated my team to attend stand-ups!</title><link href="http://localhost:4000/https:/medium.com/@suraj.rajan/how-chocolate-and-a-slack-bot-motivated-my-team-to-attend-stand-ups-a617ae98459e" rel="alternate" type="text/html" title="How chocolate and a slack-bot motivated my team to attend stand-ups!" /><published>2018-03-24T00:00:00+05:30</published><updated>2018-03-24T00:00:00+05:30</updated><id>http://localhost:4000/https:/medium.com/@suraj.rajan/chokolate</id><content type="html" xml:base="http://localhost:4000/https:/medium.com/@suraj.rajan/how-chocolate-and-a-slack-bot-motivated-my-team-to-attend-stand-ups-a617ae98459e">&lt;p&gt;How to get your employees motivated to attend the daily scrum/stand-up meets through chocolate and a simple but creative
Python chat bot on Slack.&lt;/p&gt;</content><author><name></name></author><summary type="html">How to get your employees motivated to attend the daily scrum/stand-up meets through chocolate and a simple but creative Python chat bot on Slack.</summary></entry><entry><title type="html">Chatbot framework for any customer-agent application</title><link href="http://localhost:4000/https:/github.com/skrcode/cocoa-flights" rel="alternate" type="text/html" title="Chatbot framework for any customer-agent application" /><published>2018-02-02T00:00:00+05:30</published><updated>2018-02-02T00:00:00+05:30</updated><id>http://localhost:4000/https:/github.com/skrcode/cocoaflights</id><content type="html" xml:base="http://localhost:4000/https:/github.com/skrcode/cocoa-flights">&lt;p&gt;A hobby project that failed. Although the project failed, I feel that the learnings and a bit of the code can be reused by anyone who’s interested in building chatbots for customer-agent based applications. You can read more about it in this blogpost : &lt;a href=&quot;https://medium.com/@surajkrajan95/chatbot-framework-for-any-customer-agent-application-ae675c0b56e7&quot;&gt;Cocoa Flights&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">A hobby project that failed. Although the project failed, I feel that the learnings and a bit of the code can be reused by anyone who’s interested in building chatbots for customer-agent based applications. You can read more about it in this blogpost : Cocoa Flights</summary></entry><entry><title type="html">Recursion using ReactJS Components</title><link href="http://localhost:4000/https:/medium.com/@suraj.rajan/recursion-using-reactjs-components-3c871f99fb2f" rel="alternate" type="text/html" title="Recursion using ReactJS Components" /><published>2018-01-01T00:00:00+05:30</published><updated>2018-01-01T00:00:00+05:30</updated><id>http://localhost:4000/https:/medium.com/@suraj.rajan/recursive_react_components</id><content type="html" xml:base="http://localhost:4000/https:/medium.com/@suraj.rajan/recursion-using-reactjs-components-3c871f99fb2f">&lt;p&gt;A tutorial on how to use recursion in React components. Recursive react
components enable the code to be clean, maintainble, extensible and readable.
Recursion reduces seemingly complex problems to simpler ones.
The tutorial explains recursion in React from the fundamentals along with a simple example in addition to a complex one being introduced towards the end.&lt;/p&gt;</content><author><name></name></author><summary type="html">A tutorial on how to use recursion in React components. Recursive react components enable the code to be clean, maintainble, extensible and readable. Recursion reduces seemingly complex problems to simpler ones. The tutorial explains recursion in React from the fundamentals along with a simple example in addition to a complex one being introduced towards the end.</summary></entry><entry><title type="html">Kaggle Spooky Author Identification - 0.29, Highest Public LB score for a published kernel, Beginner NLP Tutorial</title><link href="http://localhost:4000/https:/www.kaggle.com/skrcode/0-29-public-lb-score-beginner-nlp-tutorial" rel="alternate" type="text/html" title="Kaggle Spooky Author Identification - 0.29, Highest Public LB score for a published kernel, Beginner NLP Tutorial" /><published>2017-12-11T00:00:00+05:30</published><updated>2017-12-11T00:00:00+05:30</updated><id>http://localhost:4000/https:/www.kaggle.com/skrcode/kaggle_SpookyAuthor</id><content type="html" xml:base="http://localhost:4000/https:/www.kaggle.com/skrcode/0-29-public-lb-score-beginner-nlp-tutorial">&lt;p&gt;My published kernel in the Kaggle Contest, Spooky Author Identification. Highest Public LB score - 0.29 (Top 50) for a published kernel in the contest. Uses Simple Feature Engineering like Punctuation,Stop Words,Glove Sentence vectors. 
In addition, it creates stack features from simple Features such as tfidf and count vectors for words and chars. Multinomial naive bayes(mnb) is then applied with the following combination - tfidf+words+mnb,tfidf+chars+mnb,count+words+mnb,count+chars+mnb. 
Conv Nets on keras texttosequence, NNs on glove sentence vectors and Fast Text are also used as stack features. 
XGBoost, which is the final model which will use the simple and stack features as input.&lt;/p&gt;</content><author><name></name></author><summary type="html">My published kernel in the Kaggle Contest, Spooky Author Identification. Highest Public LB score - 0.29 (Top 50) for a published kernel in the contest. Uses Simple Feature Engineering like Punctuation,Stop Words,Glove Sentence vectors. In addition, it creates stack features from simple Features such as tfidf and count vectors for words and chars. Multinomial naive bayes(mnb) is then applied with the following combination - tfidf+words+mnb,tfidf+chars+mnb,count+words+mnb,count+chars+mnb. Conv Nets on keras texttosequence, NNs on glove sentence vectors and Fast Text are also used as stack features. XGBoost, which is the final model which will use the simple and stack features as input.</summary></entry><entry><title type="html">Stanford CS 224N Assignments 1,2</title><link href="http://localhost:4000/https:/github.com/skrcode/CS224N" rel="alternate" type="text/html" title="Stanford CS 224N Assignments 1,2" /><published>2017-09-09T00:00:00+05:30</published><updated>2017-09-09T00:00:00+05:30</updated><id>http://localhost:4000/https:/github.com/skrcode/cs224n</id><content type="html" xml:base="http://localhost:4000/https:/github.com/skrcode/CS224N">&lt;p&gt;Assignment Solutions to Natural Language Processing with Deep Learning- Stanford’s &lt;a href=&quot;http://web.stanford.edu/class/cs224n/syllabus.html&quot;&gt;CS 224N&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Assignment Solutions to Natural Language Processing with Deep Learning- Stanford’s CS 224N</summary></entry><entry><title type="html">Quora Indian Answer Classifier</title><link href="http://localhost:4000/https:/github.com/skrcode/Quora-Answer-Language-Classifier" rel="alternate" type="text/html" title="Quora Indian Answer Classifier" /><published>2016-12-12T00:00:00+05:30</published><updated>2016-12-12T00:00:00+05:30</updated><id>http://localhost:4000/https:/github.com/skrcode/indianenglish</id><content type="html" xml:base="http://localhost:4000/https:/github.com/skrcode/Quora-Answer-Language-Classifier">&lt;p&gt;Algorithm which classifies Quora answers into Indian or Non-Indian based on the style of writing. Indian answer dataset is taken from the novels by Chetan Bhagat viz. Five Point Someone, 3 mistakes of my life and One night at a call centre.
Non-Indian answer dataset is a collection of toefl and sat essays&lt;/p&gt;</content><author><name></name></author><summary type="html">Algorithm which classifies Quora answers into Indian or Non-Indian based on the style of writing. Indian answer dataset is taken from the novels by Chetan Bhagat viz. Five Point Someone, 3 mistakes of my life and One night at a call centre. Non-Indian answer dataset is a collection of toefl and sat essays</summary></entry><entry><title type="html">Quora Chrome Extension</title><link href="http://localhost:4000/https:/github.com/skrcode/Chrome-Extension" rel="alternate" type="text/html" title="Quora Chrome Extension" /><published>2016-12-12T00:00:00+05:30</published><updated>2016-12-12T00:00:00+05:30</updated><id>http://localhost:4000/https:/github.com/skrcode/chromeext</id><content type="html" xml:base="http://localhost:4000/https:/github.com/skrcode/Chrome-Extension">&lt;p&gt;Quora Chrome Extension which classifies Quora answers into genres such as information,stories and world affairs for improved reading experience&lt;/p&gt;

&lt;p&gt;The test data included contains data from the facebook page “Best-Of-Quora”&lt;/p&gt;

&lt;p&gt;Gets labelled training data from python nltk’s “Brown dataset”. 
Uses Google’s Word2Vec to perform meaning analysis and get data points for each word. 
Uses K means clustering to create an unsupervised model of for the list of words.
Associates each word to a cluster(centroid) and creates a bag of cluster model.
Using this bag of cluster vector for each paragraph, a RandomForest model with suitable parameter tuning is trained.
The test data is run on this model.&lt;/p&gt;

&lt;p&gt;The Chrome Extension fetches data from the Quora home page and hits the python service and retrieves the output&lt;/p&gt;</content><author><name></name></author><summary type="html">Quora Chrome Extension which classifies Quora answers into genres such as information,stories and world affairs for improved reading experience</summary></entry><entry><title type="html">Image Denoising using Edge Patch Based Dictionaries and BIRCH unsupervised clustering algorithm</title><link href="http://localhost:4000/https:/github.com/skrcode/Image-Denoising" rel="alternate" type="text/html" title="Image Denoising using Edge Patch Based Dictionaries and BIRCH unsupervised clustering algorithm" /><published>2016-04-26T00:00:00+05:30</published><updated>2016-04-26T00:00:00+05:30</updated><id>http://localhost:4000/https:/github.com/skrcode/birch</id><content type="html" xml:base="http://localhost:4000/https:/github.com/skrcode/Image-Denoising">&lt;p&gt;A technique to speed-up a nonlocal means (NLM) filter is implemented. In the original NLM filter, most of its computational time is spent on finding distances for all the patches in the search window. Here, a dictionary is built in which patches with similar photometric structures are clustered together. Dictionary is built only once with high resolution images belonging to different scenes. Since the dictionary is well organized in terms of indexing its entries, it is used to search similar patches very quickly for efficient NLM denoising.A substantial reduction in computational cost compared with the original NLM method, especially when the search window of NLM is large, without much affecting the PSNR. Second, it can be seen that by building a dictionary for edge patches as opposed to intensity patches, it is possible to reduce the dictionary size; thus, further improving the computational speed and memory requirement. The implemented method preclassifies similar patches with the same distance measure as used by NLM method. The implemented algorithm is shown to outperform other prefiltering based fast NLM algorithms computationally as well as qualitatively.&lt;/p&gt;</content><author><name></name></author><summary type="html">A technique to speed-up a nonlocal means (NLM) filter is implemented. In the original NLM filter, most of its computational time is spent on finding distances for all the patches in the search window. Here, a dictionary is built in which patches with similar photometric structures are clustered together. Dictionary is built only once with high resolution images belonging to different scenes. Since the dictionary is well organized in terms of indexing its entries, it is used to search similar patches very quickly for efficient NLM denoising.A substantial reduction in computational cost compared with the original NLM method, especially when the search window of NLM is large, without much affecting the PSNR. Second, it can be seen that by building a dictionary for edge patches as opposed to intensity patches, it is possible to reduce the dictionary size; thus, further improving the computational speed and memory requirement. The implemented method preclassifies similar patches with the same distance measure as used by NLM method. The implemented algorithm is shown to outperform other prefiltering based fast NLM algorithms computationally as well as qualitatively.</summary></entry><entry><title type="html">Improving running time of a network using segment trees</title><link href="http://localhost:4000/https:/github.com/skrcode/Network-Simulator" rel="alternate" type="text/html" title="Improving running time of a network using segment trees" /><published>2014-09-09T00:00:00+05:30</published><updated>2014-09-09T00:00:00+05:30</updated><id>http://localhost:4000/https:/github.com/skrcode/networksimulator</id><content type="html" xml:base="http://localhost:4000/https:/github.com/skrcode/Network-Simulator">&lt;p&gt;Linear networks of varying and highly volatile bandwidths are networks with links whose capacity of carrying data changes a lot due to presence of many physical parameters.
Bandwidth volatility can also occur due to factors such as Bandwidth Throttling due to interference from the Internet Service Provider or due to congestion of networks. Consequently, it becomes extremely difficult to estimate throughput for a
particular flow.
In a channel consisting of links of varying bandwidths, the link of minimum bandwidth determines the throughput of the channel. Hence, estimating the throughput when the link bandwidths are known and are varying constantly with time is a difficult challenge. This project, simulates the currently used naive methods and a more efficient method using segment trees for throughput estimation.&lt;/p&gt;</content><author><name></name></author><summary type="html">Linear networks of varying and highly volatile bandwidths are networks with links whose capacity of carrying data changes a lot due to presence of many physical parameters. Bandwidth volatility can also occur due to factors such as Bandwidth Throttling due to interference from the Internet Service Provider or due to congestion of networks. Consequently, it becomes extremely difficult to estimate throughput for a particular flow. In a channel consisting of links of varying bandwidths, the link of minimum bandwidth determines the throughput of the channel. Hence, estimating the throughput when the link bandwidths are known and are varying constantly with time is a difficult challenge. This project, simulates the currently used naive methods and a more efficient method using segment trees for throughput estimation.</summary></entry></feed>